<!DOCTYPE html> <html lang="en"><head>
<title>09. Neural Sequence Labeling</title>
<base href="..">
<meta name="pathname" content="natural-language-processing/09.-neural-sequence-labeling.html">
<meta name="description" content="Yulei's Notes - 09. Neural Sequence Labeling">
<meta property="og:title" content="09. Neural Sequence Labeling">
<meta property="og:description" content="Yulei's Notes - 09. Neural Sequence Labeling">
<meta property="og:type" content="website">
<meta property="og:url" content="natural-language-processing/09.-neural-sequence-labeling.html">
<meta property="og:image" content="undefined">
<meta charset="UTF-8"><meta property="og:site_name" content="Yulei's Notes"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes, minimum-scale=1.0, maximum-scale=5.0"><link rel="alternate" type="application/rss+xml" title="RSS Feed" href="site-lib/rss.xml"><script async="" id="webpage-script" src="site-lib/scripts/webpage.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="graph-wasm-script" src="site-lib/scripts/graph-wasm.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="graph-render-worker-script" src="site-lib/scripts/graph-render-worker.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><link rel="icon" href="site-lib/media/favicon.png"><link rel="stylesheet" href="site-lib/styles/obsidian.css"><link rel="stylesheet" href="site-lib/styles/theme.css"><link rel="preload" href="site-lib/styles/global-variable-styles.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="site-lib/styles/global-variable-styles.css"></noscript><link rel="preload" href="site-lib/styles/main-styles.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="site-lib/styles/main-styles.css"></noscript><style>body{--line-width:40em;--line-width-adaptive:40em;--file-line-width:40em;--sidebar-width:min(20em, 80vw);--collapse-arrow-size:11px;--tree-vertical-spacing:1.3em;--sidebar-margin:12px}:root{background-color:#202124}.sidebar{height:100%;font-size:14px;z-index:10;min-width:calc(var(--sidebar-width) + var(--divider-width-hover));max-width:calc(var(--sidebar-width) + var(--divider-width-hover));position:relative;overflow:hidden;overflow:clip;transition:min-width ease-in-out,max-width ease-in-out;transition-duration:.2s;contain:size}#left-sidebar{left:0}#right-sidebar{right:0}.sidebar.is-collapsed{min-width:0;max-width:0}.sidebar.floating{position:absolute}.sidebar .leaf-content{height:100%;min-width:calc(var(--sidebar-width) - var(--divider-width-hover));top:0;padding:var(--sidebar-margin);padding-top:4em;line-height:var(--line-height-tight);background-color:var(--background-secondary);transition:background-color,border-right,border-left,box-shadow;transition-duration:var(--color-fade-speed);transition-timing-function:ease-in-out;position:absolute;display:flex;flex-direction:column}.sidebar:not(.is-collapsed) .leaf-content{min-width:calc(max(100%,var(--sidebar-width)) - 3px);max-width:calc(max(100%,var(--sidebar-width)) - 3px)}#left-sidebar-content{left:0;border-top-right-radius:var(--radius-l);border-bottom-right-radius:var(--radius-l)}#right-sidebar-content{right:0;border-top-left-radius:var(--radius-l);border-bottom-left-radius:var(--radius-l)}.sidebar #left-sidebar-content,.sidebar #right-sidebar-content{contain:none!important;container-type:normal!important;animation:none!important}.sidebar:has(.leaf-content:empty):has(.topbar-content:empty){display:none}.sidebar-topbar{height:calc(2.3em + 2 * var(--sidebar-margin));width:var(--sidebar-width);padding:var(--sidebar-margin);z-index:1;position:fixed;display:flex;align-items:center;transition:width ease-in-out;transition-duration:inherit}.sidebar.is-collapsed .sidebar-topbar{width:calc(2.3em + var(--sidebar-margin) * 2)}.sidebar .sidebar-topbar.is-collapsed{width:0}#left-sidebar .sidebar-topbar{left:0;flex-direction:row;border-top-right-radius:var(--radius-l)}#right-sidebar .sidebar-topbar{right:0;flex-direction:row-reverse;border-top-left-radius:var(--radius-l)}#left-sidebar .topbar-content{margin-right:calc(2.3em + var(--sidebar-margin));flex-direction:row}#right-sidebar .topbar-content{margin-left:calc(2.3em + var(--sidebar-margin));flex-direction:row-reverse}.topbar-content{overflow:hidden visible;overflow:clip visible;width:100%;height:100%;display:flex;align-items:center;transition:inherit}.sidebar.is-collapsed .topbar-content{width:0;transition:inherit}.clickable-icon.sidebar-collapse-icon{background-color:transparent;color:var(--icon-color-focused);padding:2px!important;margin:0!important;height:100%!important;width:2.3em!important;margin-inline:0.14em!important;position:absolute}#left-sidebar .clickable-icon.sidebar-collapse-icon{transform:rotateY(180deg);right:var(--sidebar-margin)}#right-sidebar .clickable-icon.sidebar-collapse-icon{transform:rotateY(180deg);left:var(--sidebar-margin)}.clickable-icon.sidebar-collapse-icon svg.svg-icon{width:100%;height:100%}.feature-title{margin-left:1px;text-transform:uppercase;letter-spacing:.06em;margin-top:.75em;margin-bottom:.75em}.feature-header{display:flex;align-items:center;padding-top:0;font-size:1em;padding-left:0}body.floating-sidebars .sidebar{position:absolute}body{transition:background-color var(--color-fade-speed) ease-in-out}#navbar:not(:empty){display:flex;align-items:center;justify-content:space-between;padding:.5em 1em;width:100%}#main{display:flex;flex-direction:column;height:100%;width:100%;align-items:stretch;justify-content:center}#main-horizontal{display:flex;flex-direction:row;flex-grow:1;width:100%;align-items:stretch;justify-content:center}#center-content{flex-basis:100%;max-width:100%;width:100%;height:100%;display:flex;flex-direction:column;align-items:center;transition:opacity .2s ease-in-out;contain:inline-size}.hide{opacity:0!important;transition:opacity .2s ease-in-out;pointer-events:none}#center-content>.obsidian-document{padding-left:2em;padding-right:1em;margin-bottom:0;width:100%;width:-webkit-fill-available;width:-moz-available;width:fill-available;transition:background-color var(--color-fade-speed) ease-in-out;border-top-right-radius:var(--window-radius,var(--radius-m));border-top-left-radius:var(--window-radius,var(--radius-m));overflow-x:hidden!important;overflow-y:auto!important;display:flex!important;flex-direction:column!important;align-items:center!important;contain:inline-size}body #center-content>.obsidian-document>.markdown-preview-sizer{padding-bottom:80vh;width:100%;max-width:var(--line-width);flex-basis:var(--line-width);transition:background-color var(--color-fade-speed) ease-in-out;contain:inline-size}#center-content>.obsidian-document>div{width:100%!important;transition:background-color var(--color-fade-speed) ease-in-out;contain:inline-size}#center-content>.obsidian-document:not([data-type=markdown]).embed{display:flex;padding:1em;height:100%;width:100%;align-items:center;justify-content:center}#center-content>.obsidian-document:not([data-type=markdown]).embed>*{max-width:100%;max-height:100%;object-fit:contain}:not(h1,h2,h3,h4,h5,h6,li):has(> :is(.math,table)){overflow-x:auto!important}#center-content>.obsidian-document:not([data-type=markdown]){overflow-x:auto;contain:content;padding:0;margin:0;height:100%}.obsidian-document[data-type=attachment]{display:flex;flex-direction:column;align-items:center;justify-content:center;height:100%;width:100%}.obsidian-document[data-type=attachment]>*{outline:0;border:none;box-shadow:none}.obsidian-document[data-type=attachment] :is(img){max-width:90%;max-height:90%;object-fit:contain}.obsidian-document[data-type=attachment]>:is(audio){width:100%;max-width:min(90%,var(--line-width))}.obsidian-document[data-type=attachment]>:is(embed,iframe,video){width:100%;height:100%;max-width:100%;max-height:100%;object-fit:contain}.canvas-wrapper>:is(.header,.footer){z-index:100;position:absolute;display:flex;justify-content:center;flex-direction:column;width:100%;align-items:center}.scroll-highlight{position:absolute;width:100%;height:100%;pointer-events:none;z-index:1000;background-color:hsla(var(--color-accent-hsl),.25);opacity:0;padding:1em;inset:50%;translate:-50% -50%;border-radius:var(--radius-s)}</style><script defer="">async function loadIncludes(){let e=document.querySelectorAll("link[itemprop='include']");for(const t of e){let e=t.getAttribute("href");try{let o="";if(e.startsWith("https:")||e.startsWith("http:")||"file:"!=window.location.protocol){const n=await fetch(e);if(!n.ok){console.log("Could not include file: "+e),t?.remove();continue}o=await n.text()}else{const t=document.getElementById(btoa(encodeURI(e)));if(t){const e=JSON.parse(decodeURI(atob(t.getAttribute("value")??"")));o=e?.data??""}}let n=document.createRange().createContextualFragment(o);t.before(n),t.remove(),console.log("Included text: "+o),console.log("Included file: "+e)}catch(o){t?.remove(),console.log("Could not include file: "+e,o);continue}}}document.addEventListener("DOMContentLoaded",(()=>{loadIncludes()}));let isFileProtocol="file:"==location.protocol;function waitLoadScripts(e,t){let o=e.map((e=>document.getElementById(e+"-script")));!function e(n){let l=o[n],c=n+1;l?(l&&"true"!=l.getAttribute("loaded")||n<o.length&&e(c),n<o.length&&l.addEventListener("load",(()=>e(c)))):n<o.length?e(c):t()}(0)}</script></head><body class="publish css-settings-manager mod-macos is-hidden-frameless show-inline-title show-ribbon show-view-header is-focused"><script defer="">let theme=localStorage.getItem("theme")||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light");"dark"==theme?(document.body.classList.add("theme-dark"),document.body.classList.remove("theme-light")):(document.body.classList.add("theme-light"),document.body.classList.remove("theme-dark")),window.innerWidth<480?document.body.classList.add("is-phone"):window.innerWidth<768?document.body.classList.add("is-tablet"):window.innerWidth<1024?document.body.classList.add("is-small-screen"):document.body.classList.add("is-large-screen")</script><div class="parsed-feature-container" style="display: contents;"><link itemprop="include" href="site-lib/html/custom-head-content-content.html"></div><div id="main"><div id="navbar"></div><div id="main-horizontal"><div id="left-content" class="leaf" style="--sidebar-width: var(--sidebar-width-left);"><div id="left-sidebar" class="sidebar"><div class="sidebar-handle"></div><div class="sidebar-topbar"><div class="topbar-content"><div id="search-container"><div id="search-wrapper"><input enterkeyhint="search" type="search" spellcheck="false" placeholder="Search..."><div aria-label="Clear search" id="search-clear-button"></div></div></div></div><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-content-wrapper"><div id="left-sidebar-content" class="leaf-content"><link itemprop="include" href="site-lib/html/file-tree-content.html"></div></div><script defer="">let ls = document.querySelector("#left-sidebar"); ls.classList.toggle("is-collapsed", window.innerWidth < 768); ls.style.setProperty("--sidebar-width", localStorage.getItem("sidebar-left-width"));</script></div></div><div id="center-content" class="leaf"><div class="obsidian-document markdown-preview-view markdown-rendered node-insert-event is-readable-line-width allow-fold-headings allow-fold-lists show-indentation-guide show-properties" data-type="markdown"><style id="MJX-CHTML-styles">mjx-container[jax=CHTML]{line-height:0}mjx-container [space="1"]{margin-left:.111em}mjx-container [space="2"]{margin-left:.167em}mjx-container [space="3"]{margin-left:.222em}mjx-container [space="4"]{margin-left:.278em}mjx-container [space="5"]{margin-left:.333em}mjx-container [rspace="1"]{margin-right:.111em}mjx-container [rspace="2"]{margin-right:.167em}mjx-container [rspace="3"]{margin-right:.222em}mjx-container [rspace="4"]{margin-right:.278em}mjx-container [rspace="5"]{margin-right:.333em}mjx-container [size="s"]{font-size:70.7%}mjx-container [size=ss]{font-size:50%}mjx-container [size=Tn]{font-size:60%}mjx-container [size=sm]{font-size:85%}mjx-container [size=lg]{font-size:120%}mjx-container [size=Lg]{font-size:144%}mjx-container [size=LG]{font-size:173%}mjx-container [size=hg]{font-size:207%}mjx-container [size=HG]{font-size:249%}mjx-container [width=full]{width:100%}mjx-box{display:inline-block}mjx-block{display:block}mjx-itable{display:inline-table}mjx-row{display:table-row}mjx-row>*{display:table-cell}mjx-mtext{display:inline-block}mjx-mstyle{display:inline-block}mjx-merror{display:inline-block;color:red;background-color:#ff0}mjx-mphantom{visibility:hidden}mjx-assistive-mml{top:0;left:0;clip:rect(1px,1px,1px,1px);user-select:none;position:absolute!important;padding:1px 0 0!important;border:0!important;display:block!important;width:auto!important;overflow:hidden!important}mjx-assistive-mml[display=block]{width:100%!important}mjx-math{display:inline-block;text-align:left;line-height:0;text-indent:0;font-style:normal;font-weight:400;font-size:100%;font-size-adjust:none;letter-spacing:normal;border-collapse:collapse;overflow-wrap:normal;word-spacing:normal;white-space:nowrap;direction:ltr;padding:1px 0}mjx-container[jax=CHTML][display=true]{display:block;text-align:center;margin:1em 0}mjx-container[jax=CHTML][display=true][width=full]{display:flex}mjx-container[jax=CHTML][display=true] mjx-math{padding:0}mjx-container[jax=CHTML][justify=left]{text-align:left}mjx-container[jax=CHTML][justify=right]{text-align:right}mjx-mo{display:inline-block;text-align:left}mjx-stretchy-h{display:inline-table;width:100%}mjx-stretchy-h>*{display:table-cell;width:0}mjx-stretchy-h>*>mjx-c{display:inline-block;transform:scaleX(1)}mjx-stretchy-h>*>mjx-c::before{display:inline-block;width:initial}mjx-stretchy-h>mjx-ext{overflow:clip visible;width:100%}mjx-stretchy-h>mjx-ext>mjx-c::before{transform:scaleX(500)}mjx-stretchy-h>mjx-ext>mjx-c{width:0}mjx-stretchy-h>mjx-beg>mjx-c{margin-right:-.1em}mjx-stretchy-h>mjx-end>mjx-c{margin-left:-.1em}mjx-stretchy-v{display:inline-block}mjx-stretchy-v>*{display:block}mjx-stretchy-v>mjx-beg{height:0}mjx-stretchy-v>mjx-end>mjx-c{display:block}mjx-stretchy-v>*>mjx-c{transform:scaleY(1);transform-origin:left center;overflow:hidden}mjx-stretchy-v>mjx-ext{display:block;height:100%;box-sizing:border-box;border:0 solid transparent;overflow:visible clip}mjx-stretchy-v>mjx-ext>mjx-c::before{width:initial;box-sizing:border-box}mjx-stretchy-v>mjx-ext>mjx-c{transform:scaleY(500) translateY(.075em);overflow:visible}mjx-mark{display:inline-block;height:0}mjx-c{display:inline-block}mjx-utext{display:inline-block;padding:.75em 0 .2em}mjx-mi{display:inline-block;text-align:left}mjx-mn{display:inline-block;text-align:left}mjx-texatom{display:inline-block;text-align:left}mjx-c::before{display:block;width:0}.MJX-TEX{font-family:MJXZERO,MJXTEX}.TEX-B{font-family:MJXZERO,MJXTEX-B}.TEX-I{font-family:MJXZERO,MJXTEX-I}.TEX-MI{font-family:MJXZERO,MJXTEX-MI}.TEX-BI{font-family:MJXZERO,MJXTEX-BI}.TEX-S1{font-family:MJXZERO,MJXTEX-S1}.TEX-S2{font-family:MJXZERO,MJXTEX-S2}.TEX-S3{font-family:MJXZERO,MJXTEX-S3}.TEX-S4{font-family:MJXZERO,MJXTEX-S4}.TEX-A{font-family:MJXZERO,MJXTEX-A}.TEX-C{font-family:MJXZERO,MJXTEX-C}.TEX-CB{font-family:MJXZERO,MJXTEX-CB}.TEX-FR{font-family:MJXZERO,MJXTEX-FR}.TEX-FRB{font-family:MJXZERO,MJXTEX-FRB}.TEX-SS{font-family:MJXZERO,MJXTEX-SS}.TEX-SSB{font-family:MJXZERO,MJXTEX-SSB}.TEX-SSI{font-family:MJXZERO,MJXTEX-SSI}.TEX-SC{font-family:MJXZERO,MJXTEX-SC}.TEX-T{font-family:MJXZERO,MJXTEX-T}.TEX-V{font-family:MJXZERO,MJXTEX-V}.TEX-VB{font-family:MJXZERO,MJXTEX-VB}mjx-stretchy-h mjx-c,mjx-stretchy-v mjx-c{font-family:MJXZERO,MJXTEX-S1,MJXTEX-S4,MJXTEX,MJXTEX-A!important}@font-face{font-family:MJXZERO;src:url("site-lib/fonts/mathjax_zero.woff") format("woff")}@font-face{font-family:MJXTEX;src:url("site-lib/fonts/mathjax_main-regular.woff") format("woff")}@font-face{font-family:MJXTEX-B;src:url("site-lib/fonts/mathjax_main-bold.woff") format("woff")}@font-face{font-family:MJXTEX-I;src:url("site-lib/fonts/mathjax_math-italic.woff") format("woff")}@font-face{font-family:MJXTEX-MI;src:url("site-lib/fonts/mathjax_main-italic.woff") format("woff")}@font-face{font-family:MJXTEX-BI;src:url("site-lib/fonts/mathjax_math-bolditalic.woff") format("woff")}@font-face{font-family:MJXTEX-S1;src:url("site-lib/fonts/mathjax_size1-regular.woff") format("woff")}@font-face{font-family:MJXTEX-S2;src:url("site-lib/fonts/mathjax_size2-regular.woff") format("woff")}@font-face{font-family:MJXTEX-S3;src:url("site-lib/fonts/mathjax_size3-regular.woff") format("woff")}@font-face{font-family:MJXTEX-S4;src:url("site-lib/fonts/mathjax_size4-regular.woff") format("woff")}@font-face{font-family:MJXTEX-A;src:url("site-lib/fonts/mathjax_ams-regular.woff") format("woff")}@font-face{font-family:MJXTEX-C;src:url("site-lib/fonts/mathjax_calligraphic-regular.woff") format("woff")}@font-face{font-family:MJXTEX-CB;src:url("site-lib/fonts/mathjax_calligraphic-bold.woff") format("woff")}@font-face{font-family:MJXTEX-FR;src:url("site-lib/fonts/mathjax_fraktur-regular.woff") format("woff")}@font-face{font-family:MJXTEX-FRB;src:url("site-lib/fonts/mathjax_fraktur-bold.woff") format("woff")}@font-face{font-family:MJXTEX-SS;src:url("site-lib/fonts/mathjax_sansserif-regular.woff") format("woff")}@font-face{font-family:MJXTEX-SSB;src:url("site-lib/fonts/mathjax_sansserif-bold.woff") format("woff")}@font-face{font-family:MJXTEX-SSI;src:url("site-lib/fonts/mathjax_sansserif-italic.woff") format("woff")}@font-face{font-family:MJXTEX-SC;src:url("site-lib/fonts/mathjax_script-regular.woff") format("woff")}@font-face{font-family:MJXTEX-T;src:url("site-lib/fonts/mathjax_typewriter-regular.woff") format("woff")}@font-face{font-family:MJXTEX-V;src:url("site-lib/fonts/mathjax_vector-regular.woff") format("woff")}@font-face{font-family:MJXTEX-VB;src:url("site-lib/fonts/mathjax_vector-bold.woff") format("woff")}mjx-c.mjx-cD7::before{padding:.491em .778em 0 0;content:"×"}mjx-c.mjx-c1D45A.TEX-I::before{padding:.442em .878em .011em 0;content:"m"}mjx-c.mjx-c2B::before{padding:.583em .778em .082em 0;content:"+"}mjx-c.mjx-c1D45B.TEX-I::before{padding:.442em .6em .011em 0;content:"n"}mjx-c.mjx-c31::before{padding:.666em .5em 0 0;content:"1"}mjx-c.mjx-c1D410.TEX-B::before{padding:.696em .864em .193em 0;content:"Q"}mjx-c.mjx-c1D40A.TEX-B::before{padding:.686em .901em 0 0;content:"K"}mjx-c.mjx-c1D415.TEX-B::before{padding:.686em .869em .007em 0;content:"V"}mjx-c.mjx-c1D465.TEX-I::before{padding:.442em .572em .011em 0;content:"x"}mjx-c.mjx-c1D439.TEX-I::before{padding:.68em .749em 0 0;content:"F"}mjx-c.mjx-c28::before{padding:.75em .389em .25em 0;content:"("}mjx-c.mjx-c29::before{padding:.75em .389em .25em 0;content:")"}mjx-c.mjx-c210E.TEX-I::before{padding:.694em .576em .011em 0;content:"h"}mjx-c.mjx-c3D::before{padding:.583em .778em .082em 0;content:"="}</style><div class="markdown-preview-sizer markdown-preview-section"><div class="header"><h1 class="page-title heading inline-title" id="9._Neural_Sequence_Labeling_0">9. Neural Sequence Labeling</h1><div class="data-bar"></div></div><div class="markdown-preview-pusher" style="width: 1px; height: 0.1px; margin-bottom: 0px;"></div><div class="el-h2"><h2 data-heading="I. Named Entity Recognition (NER) Task" dir="auto" class="heading" id="I._Named_Entity_Recognition_(NER)_Task_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>I. Named Entity Recognition (NER) Task</h2></div><div class="el-table" dir="ltr" style="overflow-x: auto;"><table>
<thead>
<tr>
<th align="left" dir="ltr">Concept</th>
<th align="left" dir="ltr">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" dir="ltr"><strong>Named Entity</strong></td>
<td align="left" dir="ltr">An entity represented by a name, such as a person, organization, location, number, or product.</td>
</tr>
<tr>
<td align="left" dir="ltr"><strong>NER Definition</strong></td>
<td align="left" dir="ltr">The task of finding and classifying these named entities within text.</td>
</tr>
<tr>
<td align="left" dir="ltr"><strong>Utility</strong></td>
<td align="left" dir="ltr">Fundamental to NLP: used for building knowledge bases (information extraction), answering questions, and requiring special care in machine translation (e.g., transliteration or number conversion).</td>
</tr>
<tr>
<td align="left" dir="ltr"><strong>Challenges</strong></td>
<td align="left" dir="ltr">High cost of obtaining labeled data, need for comprehensive world knowledge (e.g., identifying "Sheffield Wednesday F.C." as an organization), and handling ambiguity/long context dependencies.</td>
</tr>
</tbody>
</table></div><div class="el-h2"><h2 data-heading="II. Multiword Labels and Evaluation" dir="auto" class="heading" id="II._Multiword_Labels_and_Evaluation_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>II. Multiword Labels and Evaluation</h2></div><div class="el-p"><p dir="auto">NER is typically modeled as a <strong>Sequence Labeling</strong> task, assigning one label per word.</p></div><div class="el-h3"><h3 data-heading="2.1 Span Representation" dir="auto" class="heading" id="2.1_Span_Representation_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>2.1 Span Representation</h3></div><div class="el-p"><p dir="auto">This addresses how to label entities composed of multiple words:</p></div><div class="el-table" dir="ltr" style="overflow-x: auto;"><table>
<thead>
<tr>
<th align="left" dir="ltr">Scheme</th>
<th align="left" dir="ltr">Description</th>
<th align="left" dir="ltr">Labels</th>
<th align="left" dir="ltr">Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" dir="ltr"><strong>IO</strong></td>
<td align="left" dir="ltr">Inside (NE Type) or Outside (<code>O</code>).</td>
<td align="left" dir="ltr"><a href="?query=tag:NE" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#NE">#NE</a> + 1</td>
<td align="left" dir="ltr">Cannot distinguish adjacent spans of the same entity type (e.g., two cities side-by-side).</td>
</tr>
<tr>
<td align="left" dir="ltr"><strong>BIO</strong></td>
<td align="left" dir="ltr">Begin (<code>B-Type</code>), Inside (<code>I-Type</code>), or Outside (<code>O</code>).</td>
<td align="left" dir="ltr">2 <span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-mo class="mjx-n"><mjx-c class="mjx-cD7"></mjx-c></mjx-mo></mjx-math></mjx-container></span> <a href="?query=tag:NE" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#NE">#NE</a> + 1</td>
<td align="left" dir="ltr">Commonly used, addresses the boundary ambiguity of IO.</td>
</tr>
<tr>
<td align="left" dir="ltr"><strong>BILOU</strong></td>
<td align="left" dir="ltr">Begin, Inside, Last (<code>L-Type</code>), Outside, or Unique (<code>U-Type</code>).</td>
<td align="left" dir="ltr">4 <span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-mo class="mjx-n"><mjx-c class="mjx-cD7"></mjx-c></mjx-mo></mjx-math></mjx-container></span> <a href="?query=tag:NE" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#NE">#NE</a> + 1</td>
<td align="left" dir="ltr">Provides the most specific boundary markers.</td>
</tr>
</tbody>
</table></div><div class="el-h3"><h3 data-heading="2.2 Evaluation" dir="auto" class="heading" id="2.2_Evaluation_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>2.2 Evaluation</h3></div><div class="el-p"><p dir="auto">Standard information retrieval metrics are used:</p></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span><strong>Metrics:</strong> Precision, Recall, and F1 Score (harmonic mean of Precision and Recall).</li>
<li data-line="1" dir="auto"><span class="list-bullet"></span><strong>Phrase-level Counting:</strong> A prediction is only correct if the <strong>entire span (boundary)</strong> and its <strong>type</strong> are matched exactly. This method penalizes partial overlaps.</li>
<li data-line="2" dir="auto"><span class="list-bullet"></span><strong>Token-level Counting:</strong> Counts the number of correctly labeled individual words (tokens). This method rewards partial overlaps, but tends to weigh longer entities more heavily.</li>
</ul></div><div class="el-h2"><h2 data-heading="III. Basic Neural Sequence Labeling Models" dir="auto" class="heading" id="III._Basic_Neural_Sequence_Labeling_Models_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>III. Basic Neural Sequence Labeling Models</h2></div><div class="el-p"><p dir="auto">Early methods included Hidden Markov Models (HMM) and Conditional Random Fields (CRF). Today, the focus is on Neural Sequence Models.</p></div><div class="el-h3"><h3 data-heading="3.1 Basic Components" dir="auto" class="heading" id="3.1_Basic_Components_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>3.1 Basic Components</h3></div><div class="el-p"><p dir="auto">A model typically includes 1-hot encoding, word embedding, a sequence layer (the core mechanism), and a classification layer. Training relies on the Cross-Entropy loss function.</p></div><div class="el-h3"><h3 data-heading="3.2 Context Modeling Architectures" dir="auto" class="heading" id="3.2_Context_Modeling_Architectures_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>3.2 Context Modeling Architectures</h3></div><div class="el-table" dir="ltr" style="overflow-x: auto;"><table>
<thead>
<tr>
<th align="left" dir="ltr">Architecture</th>
<th align="left" dir="ltr">Context Focus</th>
<th align="left" dir="ltr">Characteristics</th>
<th align="left" dir="ltr">Limitations</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" dir="ltr"><strong>Windowing</strong></td>
<td align="left" dir="ltr"><strong>Local Context</strong></td>
<td align="left" dir="ltr">Uses a fixed window size (<span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45A TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-math></mjx-container></span> words) around the current word. Often implemented using CNN or TDNN. Predictions are independent.</td>
<td align="left" dir="ltr">Cannot access long-distance dependencies effectively.</td>
</tr>
<tr>
<td align="left" dir="ltr"><strong>RNN</strong></td>
<td align="left" dir="ltr"><strong>Global Context</strong></td>
<td align="left" dir="ltr">Stores sequence history in a single, fixed-size hidden state. Trained via Backpropagation Through Time.</td>
<td align="left" dir="ltr">Fixed-size vector struggles to store long-range dependencies. Calculation is sequential and dependent on sequence length, preventing parallelism.</td>
</tr>
</tbody>
</table></div><div class="el-h2"><h2 data-heading="IV. Core Mechanism: Self-Attention" dir="auto" class="heading" id="IV._Core_Mechanism_Self-Attention_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>IV. Core Mechanism: Self-Attention</h2></div><div class="el-p"><p dir="auto">Self-attention was developed to overcome the RNN's limitations regarding fixed hidden state size and sequential computation.</p></div><div class="el-h3"><h3 data-heading="4.1 Attention Model (QKV)" dir="auto" class="heading" id="4.1_Attention_Model_(QKV)_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>4.1 Attention Model (QKV)</h3></div><div class="el-blockquote"><blockquote dir="auto">
<p>Q: 在自注意力机制中，查询（Query）、键（Key）和值（Value）这三个向量是如何协同工作的？<br>
A: 查询向量与所有键向量计算相似度，该相似度作为权重来对相应的值向量进行加权求和。这个过程准确地描述了缩放点积注意力的核心：查询当前位置需要关注哪些其他位置（通过与键的相似度），然后汇集这些位置的信息（通过对值的加权求和）。</p>
</blockquote></div><div class="el-p"><p dir="auto">The mechanism is inspired by database retrieval:</p></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span><strong>Query (<span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D410 TEX-B"></mjx-c></mjx-mi></mjx-texatom></mjx-math></mjx-container></span>):</strong> Used to query the other states in the sequence.</li>
<li data-line="1" dir="auto"><span class="list-bullet"></span><strong>Key (<span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D40A TEX-B"></mjx-c></mjx-mi></mjx-texatom></mjx-math></mjx-container></span>):</strong> Used for comparison to determine relevance.</li>
<li data-line="2" dir="auto"><span class="list-bullet"></span><strong>Value (<span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D415 TEX-B"></mjx-c></mjx-mi></mjx-texatom></mjx-math></mjx-container></span>):</strong> The components that are summed up to form the output.</li>
<li data-line="3" dir="auto"><span class="list-bullet"></span><strong>Calculation:</strong> The attention score (energy function) is typically calculated using the <strong>Scaled Dot-Product</strong>. The result is normalized using Softmax to create a probability distribution, which prevents gradient vanishing/exploding. The final output is the weighted sum of the values.</li>
</ul></div><div class="el-h3"><h3 data-heading="4.2 Multi-head Attention" dir="auto" class="heading" id="4.2_Multi-head_Attention_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>4.2 Multi-head Attention</h3></div><div class="el-p"><p dir="auto">This technique allows the model to focus on different aspects of the input simultaneously. It splits the hidden state into several "heads," calculating attention independently for each sub-vector, and concatenating the results. The total number of model parameters remains unchanged.</p></div><div class="el-h3"><h3 data-heading="4.3 Positional Information" dir="auto" class="heading" id="4.3_Positional_Information_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>4.3 Positional Information</h3></div><div class="el-p"><p dir="auto">Self-attention treats the input as a Bag-of-Words, losing vital sequence order. Therefore, <strong>Positional Encoding</strong> is required.</p></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span><strong>Trigonometric Functions:</strong> Adds sine and cosine functions to the word embeddings based on position. This periodic feature allows the model to extrapolate to unseen sequence lengths.</li>
<li data-line="1" dir="auto"><span class="list-bullet"></span><strong>Rotary Positional Encodings (ROPE):</strong> Rotates the Query and Key vectors based on absolute position. The goal is to ensure the final dot product depends only on the relative positions between words. This is applied in each layer.</li>
</ul></div><div class="el-h2"><h2 data-heading="V. Advanced Architectures and Comparison" dir="auto" class="heading" id="V._Advanced_Architectures_and_Comparison_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>V. Advanced Architectures and Comparison</h2></div><div class="el-h3"><h3 data-heading="5.1 Advanced Techniques" dir="auto" class="heading" id="5.1_Advanced_Techniques_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>5.1 Advanced Techniques</h3></div><div class="el-ol"><ol>
<li data-line="0" dir="auto"><strong>Multi-layer:</strong> Stacking sequence layers increases the model's capacity and depth.</li>
<li data-line="1" dir="auto"><strong>Residual Connection:</strong> Adds the input vector (<span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math></mjx-container></span>) to the output of a sub-layer (<span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math></mjx-container></span>) (<span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c class="mjx-c210E TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="4"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math></mjx-container></span>). This stabilizes the gradient flow, enabling the training of very deep networks.</li>
</ol></div><div class="el-h3"><h3 data-heading="5.2 Directionality and Receptive Field" dir="auto" class="heading" id="5.2_Directionality_and_Receptive_Field_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>5.2 Directionality and Receptive Field</h3></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span><strong>Direction:</strong> RNNs are inherently unidirectional (left-to-right). <strong>Bidirectional RNNs (BiRNNs)</strong> combine a forward and a backward RNN to capture context from both directions. Self-attention and TDNN/CNN have no inherent direction.</li>
<li data-line="1" dir="auto"><span class="list-bullet"></span><strong>Receptive Field (Context Access):</strong> TDNN/CNN only access local context; RNNs access the previous sequence; and self-attention accesses the entire input sequence at once.</li>
</ul></div><div class="el-h3"><h3 data-heading="5.3 Model Types and Consistency" dir="auto" class="heading" id="5.3_Model_Types_and_Consistency_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>5.3 Model Types and Consistency</h3></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span><strong>Non-Autoregressive Models (e.g., standard RNN output):</strong> Output predictions are independent of previous label predictions. They suffer from problems like inconsistent or repeated labels.</li>
<li data-line="1" dir="auto"><span class="list-bullet"></span><strong>Autoregressive Models:</strong> Current label prediction relies on the label predicted in the previous step.</li>
<li data-line="2" dir="auto"><span class="list-bullet"></span><strong>RNN + CRF:</strong> To ensure label consistency, a CRF (Conditional Random Field) layer is often placed on top of a neural model. The CRF learns the legal transitions between labels (e.g., an "I-City" cannot follow a "B-Person"), enforcing global output consistency.</li>
</ul></div><div class="footer"><div class="data-bar"></div></div></div></div></div><div id="right-content" class="leaf" style="--sidebar-width: var(--sidebar-width-right);"><div id="right-sidebar" class="sidebar"><div class="sidebar-handle"></div><div class="sidebar-topbar"><div class="topbar-content"><label class="theme-toggle-container" for="theme-toggle-input" id=""><input class="theme-toggle-input" type="checkbox" id="theme-toggle-input"><div class="toggle-background"></div></label></div><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-content-wrapper"><div id="right-sidebar-content" class="leaf-content"><div class="graph-view-wrapper"><div class="feature-header"><div class="feature-title">Interactive Graph</div></div><div class="graph-view-placeholder">
		<div class="graph-view-container">
			<div class="graph-icon graph-expand" role="button" aria-label="Expand" data-tooltip-position="top"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><line x1="7" y1="17" x2="17" y2="7"></line><polyline points="7 7 17 7 17 17"></polyline></svg></div>
			<div class="graph-icon graph-global" role="button" aria-label="Global Graph" data-tooltip-position="top"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-git-fork"><circle cx="12" cy="18" r="3"></circle><circle cx="6" cy="6" r="3"></circle><circle cx="18" cy="6" r="3"></circle><path d="M18 9v2c0 .6-.4 1-1 1H7c-.6 0-1-.4-1-1V9"></path><path d="M12 12v3"></path></svg></div>
			<canvas id="graph-canvas" class="hide" width="512px" height="512px"></canvas>
		</div>
		</div></div><div id="outline" class=" tree-container"><div class="feature-header"><div class="feature-title">Table Of Contents</div><button class="clickable-icon nav-action-button tree-collapse-all" aria-label="Collapse All"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></svg></button></div><div class="tree-item mod-collapsible" data-depth="1"><a class="tree-item-self is-clickable mod-collapsible" href="#9._Neural_Sequence_Labeling_0" data-path="#9._Neural_Sequence_Labeling_0"><div class="tree-item-icon collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><div class="tree-item-inner heading-link" heading-name="9. Neural Sequence Labeling">9. Neural Sequence Labeling</div></a><div class="tree-item-children"><div class="tree-item" data-depth="2"><a class="tree-item-self is-clickable" href="#I._Named_Entity_Recognition_(NER)_Task_0" data-path="#I._Named_Entity_Recognition_(NER)_Task_0"><div class="tree-item-inner heading-link" heading-name="I. Named Entity Recognition (NER) Task">I. Named Entity Recognition (NER) Task</div></a><div class="tree-item-children"></div></div><div class="tree-item mod-collapsible" data-depth="2"><a class="tree-item-self is-clickable mod-collapsible" href="#II._Multiword_Labels_and_Evaluation_0" data-path="#II._Multiword_Labels_and_Evaluation_0"><div class="tree-item-icon collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><div class="tree-item-inner heading-link" heading-name="II. Multiword Labels and Evaluation">II. Multiword Labels and Evaluation</div></a><div class="tree-item-children"><div class="tree-item" data-depth="3"><a class="tree-item-self is-clickable" href="#2.1_Span_Representation_0" data-path="#2.1_Span_Representation_0"><div class="tree-item-inner heading-link" heading-name="2.1 Span Representation">2.1 Span Representation</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="3"><a class="tree-item-self is-clickable" href="#2.2_Evaluation_0" data-path="#2.2_Evaluation_0"><div class="tree-item-inner heading-link" heading-name="2.2 Evaluation">2.2 Evaluation</div></a><div class="tree-item-children"></div></div></div></div><div class="tree-item mod-collapsible" data-depth="2"><a class="tree-item-self is-clickable mod-collapsible" href="#III._Basic_Neural_Sequence_Labeling_Models_0" data-path="#III._Basic_Neural_Sequence_Labeling_Models_0"><div class="tree-item-icon collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><div class="tree-item-inner heading-link" heading-name="III. Basic Neural Sequence Labeling Models">III. Basic Neural Sequence Labeling Models</div></a><div class="tree-item-children"><div class="tree-item" data-depth="3"><a class="tree-item-self is-clickable" href="#3.1_Basic_Components_0" data-path="#3.1_Basic_Components_0"><div class="tree-item-inner heading-link" heading-name="3.1 Basic Components">3.1 Basic Components</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="3"><a class="tree-item-self is-clickable" href="#3.2_Context_Modeling_Architectures_0" data-path="#3.2_Context_Modeling_Architectures_0"><div class="tree-item-inner heading-link" heading-name="3.2 Context Modeling Architectures">3.2 Context Modeling Architectures</div></a><div class="tree-item-children"></div></div></div></div><div class="tree-item mod-collapsible" data-depth="2"><a class="tree-item-self is-clickable mod-collapsible" href="#IV._Core_Mechanism_Self-Attention_0" data-path="#IV._Core_Mechanism_Self-Attention_0"><div class="tree-item-icon collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><div class="tree-item-inner heading-link" heading-name="IV. Core Mechanism: Self-Attention">IV. Core Mechanism: Self-Attention</div></a><div class="tree-item-children"><div class="tree-item" data-depth="3"><a class="tree-item-self is-clickable" href="#4.1_Attention_Model_(QKV)_0" data-path="#4.1_Attention_Model_(QKV)_0"><div class="tree-item-inner heading-link" heading-name="4.1 Attention Model (QKV)">4.1 Attention Model (QKV)</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="3"><a class="tree-item-self is-clickable" href="#4.2_Multi-head_Attention_0" data-path="#4.2_Multi-head_Attention_0"><div class="tree-item-inner heading-link" heading-name="4.2 Multi-head Attention">4.2 Multi-head Attention</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="3"><a class="tree-item-self is-clickable" href="#4.3_Positional_Information_0" data-path="#4.3_Positional_Information_0"><div class="tree-item-inner heading-link" heading-name="4.3 Positional Information">4.3 Positional Information</div></a><div class="tree-item-children"></div></div></div></div><div class="tree-item mod-collapsible" data-depth="2"><a class="tree-item-self is-clickable mod-collapsible" href="#V._Advanced_Architectures_and_Comparison_0" data-path="#V._Advanced_Architectures_and_Comparison_0"><div class="tree-item-icon collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><div class="tree-item-inner heading-link" heading-name="V. Advanced Architectures and Comparison">V. Advanced Architectures and Comparison</div></a><div class="tree-item-children"><div class="tree-item" data-depth="3"><a class="tree-item-self is-clickable" href="#5.1_Advanced_Techniques_0" data-path="#5.1_Advanced_Techniques_0"><div class="tree-item-inner heading-link" heading-name="5.1 Advanced Techniques">5.1 Advanced Techniques</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="3"><a class="tree-item-self is-clickable" href="#5.2_Directionality_and_Receptive_Field_0" data-path="#5.2_Directionality_and_Receptive_Field_0"><div class="tree-item-inner heading-link" heading-name="5.2 Directionality and Receptive Field">5.2 Directionality and Receptive Field</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="3"><a class="tree-item-self is-clickable" href="#5.3_Model_Types_and_Consistency_0" data-path="#5.3_Model_Types_and_Consistency_0"><div class="tree-item-inner heading-link" heading-name="5.3 Model Types and Consistency">5.3 Model Types and Consistency</div></a><div class="tree-item-children"></div></div></div></div></div></div></div></div></div><script defer="">let rs = document.querySelector("#right-sidebar"); rs.classList.toggle("is-collapsed", window.innerWidth < 768); rs.style.setProperty("--sidebar-width", localStorage.getItem("sidebar-right-width"));</script></div></div></div></div></body></html>